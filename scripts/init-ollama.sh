#!/bin/bash

# Script para inicializar Ollama con modelos necesarios
echo "üöÄ Inicializando Ollama para GTFS AI Generator..."

# Verificar si Ollama est√° corriendo
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "‚ùå Ollama no est√° corriendo. Iniciando Ollama..."
    docker-compose up -d ollama
    sleep 10
fi

# Lista de modelos recomendados (de menor a mayor tama√±o)
MODELS=(
    "llama2:7b"      # Modelo base recomendado
    "llama2:13b"     # Modelo m√°s grande para mejor calidad
    "codellama:7b"   # Modelo especializado en c√≥digo
    "mistral:7b"     # Alternativa eficiente
)

echo "üì• Descargando modelos de Ollama..."

for model in "${MODELS[@]}"; do
    echo "Descargando $model..."
    docker exec gtfs-ollama ollama pull $model
    
    if [ $? -eq 0 ]; then
        echo "‚úÖ $model descargado exitosamente"
    else
        echo "‚ùå Error descargando $model"
    fi
done

echo "üîß Configurando modelo por defecto..."
docker exec gtfs-ollama ollama list

echo "‚úÖ Inicializaci√≥n de Ollama completada!"
echo ""
echo "Modelos disponibles:"
docker exec gtfs-ollama ollama list

echo ""
echo "Para usar un modelo espec√≠fico, actualiza la variable OLLAMA_MODEL en tu archivo .env"
echo "Ejemplo: OLLAMA_MODEL=llama2:7b"
